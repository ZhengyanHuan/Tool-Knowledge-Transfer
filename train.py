import logging
import os
import random
import time
from typing import List, Union

import numpy as np
import torch

import configs
from my_helpers.data_helpers import select_context_for_experiment, fill_missing_params
from my_helpers.pipeline import run_pipeline
from my_helpers.viz_helpers import viz_test_objects_embedding
from transfer_class import Tool_Knowledge_transfer_class

encoder_pt_name = f"tmp_myencoder.pt"
clf_pt_name = f"tmp_myclassifier.pt"


def train_k_fold(train_val_obj_list: List[str], number_of_folds: int, loss_func: str, data_name: str,
                 grid: dict, pipe_settings=dict, val_size=4, no_overlap_sample=True):
    '''
    cross validation split on objects: some objects for train, the rest objects for val
    Assume that the last 3 objects are unknown to the tool, we use the 12 known ones to split train and val.
    '''
    if no_overlap_sample:
        assert len(train_val_obj_list) % number_of_folds == 0, (f"can't split {len(train_val_obj_list)} objects into "
                                                                f"{number_of_folds} folds without overlap!")
        num_obj_per_fold = len(train_val_obj_list) // number_of_folds
    else:
        num_obj_per_fold = val_size

    best_acc = -1
    best_acc_std = -1
    best_alpha = -1
    best_lr_en = -1
    rand_guess_acc = 1 / num_obj_per_fold

    pipe_settings.update({'save_temp_model': False, 'viz_dataset': False, 'viz_share_space': False, 'save_fig': False})
    logging.info("###########################Grid Search Start###########################")
    search_start_time = time.time()
    num_grid_combo = 0

    for alpha in grid['alpha_list']:
        for lr_encoder in grid['lr_en_list']:
            num_grid_combo += 1
            hyparams = {'TL_margin': alpha, 'lr_encoder': lr_encoder}
            logging.info("Learning rate for the encoder is:  " + str(lr_encoder))
            logging.info("TL margin is:  " + str(alpha))
            logging.info(f"========================= {number_of_folds}fold cv start=========================")
            acc_list = []
            cv_start_time = time.time()
            for fold_idx in range(number_of_folds):
                random.seed(configs.rand_seed + fold_idx)  # same splits for all hyperparam combos
                logging.info(f"-----------fold {fold_idx + 1}/{number_of_folds} start-----------")
                fold_start_time = time.time()
                if no_overlap_sample:  # normal k fold
                    val_obj_list = train_val_obj_list[fold_idx * num_obj_per_fold: (fold_idx + 1) * num_obj_per_fold]
                else:  # random select val objs
                    val_obj_list = random.sample(train_val_obj_list, val_size)
                logging.debug(f"num_grid_combo: {num_grid_combo}, fold_idx: {fold_idx}, val_obj_list: {val_obj_list}")
                train_obj_list = [item for item in train_val_obj_list if item not in val_obj_list]
                new_context = {'old_object_list': train_obj_list, 'new_object_list': val_obj_list}
                result = run_pipeline(loss_func=loss_func, data_name=data_name,
                                      orig_context=new_context, pipe_settings=pipe_settings, hyparams=hyparams)

                acc_list.append(result["test_acc"])
                logging.info(f"üëâ fold {fold_idx + 1}/{number_of_folds} val_obj: {val_obj_list} \n"
                             f"TL margin: {alpha}, lr: {lr_encoder}, val accuracy: {result['test_acc'] * 100:.2f}%, "
                             f"random guess accuracy: {rand_guess_acc * 100:.1f}%")

                logging.info(f"‚òëÔ∏è total time used for {fold_idx+1}th fold: "
                             f"{round((time.time() - fold_start_time) // 60)} min "
                             f"{(time.time() - fold_start_time) % 60:.1f} sec.")

            avg_acc = np.mean(acc_list)
            std_acc = np.std(acc_list)
            if avg_acc > best_acc:
                best_acc = avg_acc
                best_acc_std = std_acc
                best_alpha = alpha
                best_lr_en = lr_encoder

            logging.info(f"‚òëÔ∏è total time for {number_of_folds}fold cv: {round((time.time() - cv_start_time) // 60)} min "
                         f"{(time.time() - cv_start_time) % 60:.1f} sec.")

    logging.info(f"‚úÖ The best avg val accuracy is: {best_acc * 100:.1f}%, best_alpha: {best_alpha}, "
                 f"best_lr_en: {best_lr_en}, random guess accuracy: {rand_guess_acc * 100:.1f}%")

    logging.info(f"‚úÖ total time for grid search for for {num_grid_combo} combinations ({number_of_folds} cv each): "
                 f"{round((time.time() - search_start_time) // 60)} min "
                 f"{(time.time() - search_start_time) % 60:.1f} sec.")

    return {
        "best_val_acc": best_acc,
        "best_val_acc_std": best_acc_std,
        "best_alpha": best_alpha,
        "best_lr_en": best_lr_en,
    }


def train_fixed_param(train_val_obj_list: List[str], test_obj_list: List[str], loss_func: str, data_name: str,
                      hyparams: dict, pipe_settings: dict, test_name="fold0"):
    logging.warning("train_fixed_param function currently only applies the best TL alpha and training learning rate"
                    ", all other hyper-params are by default from configs.")

    test_enc_pt_folder = './saved_model/encoder/test/'
    test_clf_pt_folder = './saved_model/classifier/test/'
    if not os.path.exists(test_enc_pt_folder):
        os.makedirs(test_enc_pt_folder)
    if not os.path.exists(test_clf_pt_folder):
        os.makedirs(test_clf_pt_folder)
    pipe_settings.update(
        {'viz_dataset': False, 'viz_share_space': False, 'save_fig': True,
         'enc_pt_folder': test_enc_pt_folder, 'encoder_pt_name': f"{test_name}_{configs.encoder_pt_name}",
         'clf_pt_folder': test_clf_pt_folder, "clf_pt_name": f"{test_name}_{configs.clf_pt_name}"})

    context = {'old_object_list': train_val_obj_list, 'new_object_list': test_obj_list}
    result = run_pipeline(loss_func=loss_func, data_name=data_name,
                          orig_context=context, pipe_settings=pipe_settings, hyparams=hyparams)

    return result["test_acc"]
